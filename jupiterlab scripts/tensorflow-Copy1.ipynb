{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d897dff-f170-41cc-87de-5f5305fa73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import cv2 \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from PIL import Image\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2hsv\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image # importing image module \n",
    "import numpy as np \n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bcba36-a8bb-4c41-a194-87b732bd7b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 841 files belonging to 6 classes.\n",
      "Using 757 files for training.\n",
      "Found 841 files belonging to 6 classes.\n",
      "Using 84 files for validation.\n",
      "['NitrogenHigh', 'NitrogenLow', 'PhosphorusHigh', 'PhosphorusLow', 'PotassiumHigh', 'PotassiumLow']\n"
     ]
    }
   ],
   "source": [
    "full_dir = \"E:/User Document/processed3\"\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  full_dir,\n",
    "  validation_split=0.1,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  full_dir,\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795bcfe3-d606-4165-be28-462a6afbc6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x00000128580A45E0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e629c761-4425-4565-9dae-38f5b7062a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " random_rotation (RandomRota  (None, 22, 22, 64)       0         \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,989,414\n",
      "Trainable params: 3,989,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303acb00-8482-4e17-a645-67fe43ffff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 15s 575ms/step - loss: 1.4715 - accuracy: 0.3554 - val_loss: 1.3179 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 14s 565ms/step - loss: 1.1826 - accuracy: 0.4676 - val_loss: 1.2831 - val_accuracy: 0.4048\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 13s 561ms/step - loss: 1.0813 - accuracy: 0.5099 - val_loss: 1.1307 - val_accuracy: 0.4762\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 14s 571ms/step - loss: 0.9946 - accuracy: 0.5852 - val_loss: 1.2310 - val_accuracy: 0.4881\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 14s 566ms/step - loss: 0.9438 - accuracy: 0.5971 - val_loss: 1.1958 - val_accuracy: 0.4762\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 13s 545ms/step - loss: 0.8726 - accuracy: 0.6473 - val_loss: 0.9836 - val_accuracy: 0.6190\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 13s 559ms/step - loss: 0.7964 - accuracy: 0.6513 - val_loss: 0.9467 - val_accuracy: 0.6071\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 14s 589ms/step - loss: 0.7436 - accuracy: 0.6962 - val_loss: 1.0616 - val_accuracy: 0.5119\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 13s 556ms/step - loss: 0.7445 - accuracy: 0.6975 - val_loss: 0.9867 - val_accuracy: 0.6310\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 13s 556ms/step - loss: 0.7249 - accuracy: 0.6843 - val_loss: 0.9065 - val_accuracy: 0.6548\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2839c9cf-06f2-4c39-8219-170f692a63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    #img = img1.Rescaling(1./255, input_shape=(img_height, img_width, 3))\n",
    "    img_tensor = np.array(img)                    #       # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 1./255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92676357-93b0-4be8-b24c-2220b17d6d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.6322722 , -0.18940586, -0.1327353 ,  1.494361  ,  0.3768516 ,\n",
       "         3.8904536 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "#E:/User Document/processed2/NitrogenLow/NitrogenLow3.jpg\n",
    "#E:/User Document/processed2/PotassiumLow/164.jpg\n",
    "#E:/User Document/processed2/PhosphorusHigh/19.jpg\n",
    "image = Image.open('E:/User Document/processed2/PotassiumLow/164.jpg')\n",
    "image = image.resize((180, 180))\n",
    "image = np.array(image)\n",
    "img_tensor = np.expand_dims(image, axis=0)    \n",
    "model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ec5a69-bd91-4b5c-82bf-c6bdff854180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('E:/User Document/my_model5.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d78d20-9151-4f4b-8a3d-fd5d487c9c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be44a0-bac2-48f3-916e-d5dba05572d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
